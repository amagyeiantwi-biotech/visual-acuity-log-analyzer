# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18MlJRu1aMCvIPF9yOIjUzymoz6Nut3L3
"""

# ============================================================
# Visual Acuity Log Analyzer — Realistic Cohort + Polished Plots
# Single all-in-one Colab cell (upload Excel/CSV when prompted)
# ============================================================

# 0) Install deps (quiet)
!pip install -q pandas numpy matplotlib openpyxl

# 1) Imports & global settings
import os, io, numpy as np, pandas as pd, matplotlib.pyplot as plt

# ---- Settings you can tweak ----
EXCEL_NAME   = "visual_acuity_analyzer.xlsx"   # if present, used automatically
CSV_NAME     = "visual_acuity_logs.csv"        # fallback if Excel not present
N_EXAMPLES   = 5                                # number of patient trend plots to show/save
STABLE_BAND  = 0.01                             # +/- Decimal VA change considered Stable
# Target distribution for the *demo* (adjusted) cohort
TARGET_PCT_IMPROVED = 0.70
TARGET_PCT_STABLE   = 0.20
TARGET_PCT_WORSENED = 0.10
DO_DOWNLOAD = False                             # set True to auto-download outputs

# Plot aesthetics (for LinkedIn clarity)
TITLE_FONTSIZE = 15
LABEL_FONTSIZE = 12
TICK_FONTSIZE  = 11
FIGSIZE        = (6.5, 4.5)
DPI_SAVE       = 180

# 2) Helper functions
def parse_snellen(s: str):
    """Return (numerator, denominator) from '20/40'."""
    if not isinstance(s, str) or "/" not in s:
        raise ValueError(f"Snellen like '20/40' expected, got: {s}")
    a, b = s.split("/", 1)
    return float(a.strip()), float(b.strip())

def snellen_to_decimal(s: str) -> float:
    """20/x -> 20/x (higher is better)."""
    a, b = parse_snellen(s)
    return a / b

def snellen_to_logmar(s: str) -> float:
    """log10(x/20), lower is better."""
    _, b = parse_snellen(s)
    return float(np.log10(b / 20.0))

def decimal_to_snellen_den(decimal_val: float) -> int:
    """Approximate decimal acuity back to a common Snellen denominator for display."""
    if decimal_val <= 0: decimal_val = 0.1
    den_est = int(round(20 / decimal_val))
    common = [20, 25, 30, 40, 50, 60, 70, 80, 100]
    return min(common, key=lambda x: abs(x - den_est))

def load_data():
    """Load Excel or CSV (or prompt upload). Expect PatientID, Date, SnellenVA."""
    from google.colab import files
    if os.path.exists(EXCEL_NAME):
        df = pd.read_excel(EXCEL_NAME, parse_dates=["Date"]); used = EXCEL_NAME
    elif os.path.exists(CSV_NAME):
        df = pd.read_csv(CSV_NAME, parse_dates=["Date"]); used = CSV_NAME
    else:
        print("Upload your data file (Excel/CSV) with columns: PatientID, Date, SnellenVA")
        uploaded = files.upload()
        fname = list(uploaded.keys())[0]; used = fname
        if fname.lower().endswith((".xlsx", ".xls")):
            df = pd.read_excel(io.BytesIO(uploaded[fname]), parse_dates=["Date"])
        else:
            df = pd.read_csv(io.BytesIO(uploaded[fname]), parse_dates=["Date"])
    needed = {"PatientID", "Date", "SnellenVA"}
    if not needed.issubset(df.columns):
        raise ValueError(f"Expected columns {needed}, found {set(df.columns)} in {used}")
    df["PatientID"] = df["PatientID"].astype(str)
    df = df.sort_values(["PatientID", "Date"]).reset_index(drop=True)
    print(f"[Loaded] {used}  →  rows={len(df)}  patients={df['PatientID'].nunique()}")
    return df

def summarize(df: pd.DataFrame):
    """Add Decimal/logMAR to df and return per-patient first/last summary."""
    out = df.copy()
    out["DecimalVA"] = out["SnellenVA"].apply(snellen_to_decimal)
    out["logMAR"]    = out["SnellenVA"].apply(snellen_to_logmar)

    first = out.groupby("PatientID").first()
    last  = out.groupby("PatientID").last()
    summary = pd.DataFrame({
        "First_Snellen": first["SnellenVA"],
        "Last_Snellen":  last["SnellenVA"],
        "First_Decimal": first["DecimalVA"],
        "Last_Decimal":  last["DecimalVA"],
        "First_logMAR":  first["logMAR"],
        "Last_logMAR":   last["logMAR"],
    })
    summary["Decimal_Change"] = summary["Last_Decimal"] - summary["First_Decimal"]
    bins   = [-np.inf, -STABLE_BAND, STABLE_BAND, np.inf]
    labels = ["Worsened", "Stable", "Improved"]
    summary["Outcome"] = pd.cut(summary["Decimal_Change"], bins=bins, labels=labels)
    return out, summary

# 3) Load original data and summarize
df, summary = summarize(load_data())
print("\nOriginal cohort outcome counts:")
orig_counts = summary["Outcome"].value_counts().reindex(["Improved","Stable","Worsened"]).fillna(0)
print(orig_counts)

# 4) Build a *realistic* adjusted cohort (df2) by modifying LAST visit for subsets of patients
df2 = df.copy()
pids = df2["PatientID"].unique()
np.random.seed(7)  # reproducible
np.random.shuffle(pids)
n = len(pids)

n_worse  = int(round(TARGET_PCT_WORSENED * n))
n_stable = int(round(TARGET_PCT_STABLE   * n))
# remainder improved
worsen_ids  = set(pids[:n_worse])
stable_ids  = set(pids[n_worse:n_worse+n_stable])
improve_ids = set(pids[n_worse+n_stable:])

# First visit lookups
first_rows   = df2.groupby("PatientID").first()
first_decimal = first_rows["SnellenVA"].apply(snellen_to_decimal).to_dict()

# Index of each patient's last row
last_idx = df2.groupby("PatientID")["Date"].idxmax()

# Apply adjustments
for pid in pids:
    idx  = last_idx[pid]
    fdec = first_decimal[pid]
    if pid in worsen_ids:
        new_dec = max(0.1, fdec * np.random.uniform(0.85, 0.90))  # 10–15% worse
        new_den = decimal_to_snellen_den(new_dec)
        df2.at[idx, "SnellenVA"] = f"20/{new_den}"
    elif pid in stable_ids:
        f_s = df2[df2["PatientID"]==pid].iloc[0]["SnellenVA"]
        df2.at[idx, "SnellenVA"] = f_s
    else:
        # Ensure slight improvement if last isn't already better
        last_dec_now = snellen_to_decimal(df2.at[idx, "SnellenVA"])
        if last_dec_now <= fdec:
            new_dec = min(1.0, fdec * np.random.uniform(1.03, 1.07))
            new_den = decimal_to_snellen_den(new_dec)
            df2.at[idx, "SnellenVA"] = f"20/{new_den}"

# 5) Summarize adjusted cohort
df2, summary2 = summarize(df2)
print("\nAdjusted cohort outcome counts (target realism):")
counts2 = summary2["Outcome"].value_counts().reindex(["Improved","Stable","Worsened"]).fillna(0)
print(counts2)

# 6) Display first few rows of adjusted summary
from IPython.display import display
display(summary2.head(10))

# 7) Polished outcomes bar chart (adjusted)
plt.figure(figsize=FIGSIZE)
ax = counts2.plot(kind="bar", color=["#2ca02c", "#1f77b4", "#d62728"])  # green, blue, red
ax.set_title("Visual Acuity Outcomes (Adjusted: First → Last)", fontsize=TITLE_FONTSIZE)
ax.set_ylabel("Number of Patients", fontsize=LABEL_FONTSIZE)
ax.set_xlabel("Outcome", fontsize=LABEL_FONTSIZE)
ax.tick_params(axis="both", labelsize=TICK_FONTSIZE)
ax.grid(axis="y", alpha=0.3)

# Add count labels above bars
for p in ax.patches:
    ax.text(p.get_x() + p.get_width()/2, p.get_height() + 0.5,
            f"{int(p.get_height())}", ha="center", va="bottom", fontsize=12)

plt.tight_layout()
plt.show()

# Save bar chart (PNG)
plt.figure(figsize=FIGSIZE)
ax = counts2.plot(kind="bar", color=["#2ca02c", "#1f77b4", "#d62728"])
ax.set_title("Visual Acuity Outcomes (Adjusted: First → Last)", fontsize=TITLE_FONTSIZE)
ax.set_ylabel("Number of Patients", fontsize=LABEL_FONTSIZE)
ax.set_xlabel("Outcome", fontsize=LABEL_FONTSIZE)
ax.tick_params(axis="both", labelsize=TICK_FONTSIZE)
ax.grid(axis="y", alpha=0.3)
for p in ax.patches:
    ax.text(p.get_x() + p.get_width()/2, p.get_height() + 0.5,
            f"{int(p.get_height())}", ha="center", va="bottom", fontsize=12)
plt.tight_layout()
plt.savefig("va_outcomes_summary_adjusted.png", dpi=DPI_SAVE)
plt.close()
print("[Saved] va_outcomes_summary_adjusted.png")

# 8) Polished patient trend plots (adjusted)
example_ids = list(summary2.index[:N_EXAMPLES])
for pid in example_ids:
    sub = df2[df2["PatientID"]==pid]
    plt.figure(figsize=FIGSIZE)
    plt.plot(sub["Date"], sub["DecimalVA"], marker="o")
    plt.title(f"Decimal VA over time – {pid} (higher = better)", fontsize=TITLE_FONTSIZE)
    plt.xlabel("Date", fontsize=LABEL_FONTSIZE)
    plt.ylabel("Decimal VA", fontsize=LABEL_FONTSIZE)
    plt.xticks(rotation=30)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    # Save PNG
    plt.figure(figsize=FIGSIZE)
    plt.plot(sub["Date"], sub["DecimalVA"], marker="o")
    plt.title(f"Decimal VA over time – {pid} (higher = better)", fontsize=TITLE_FONTSIZE)
    plt.xlabel("Date", fontsize=LABEL_FONTSIZE)
    plt.ylabel("Decimal VA", fontsize=LABEL_FONTSIZE)
    plt.xticks(rotation=30)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{pid}_trend_adjusted.png", dpi=DPI_SAVE)
    plt.close()
print(f"[Saved] {len(example_ids)} trend charts: {', '.join(example_ids)}")

# 9) Save CSV summaries (original + adjusted)
summary.to_csv("va_summary_by_patient_original.csv", index=True)
summary2.to_csv("va_summary_by_patient_adjusted.csv", index=True)
print("[Saved] va_summary_by_patient_original.csv")
print("[Saved] va_summary_by_patient_adjusted.csv")

# 10) Optional: auto-download key files
if DO_DOWNLOAD:
    from google.colab import files
    files.download("va_outcomes_summary_adjusted.png")
    files.download("va_summary_by_patient_original.csv")
    files.download("va_summary_by_patient_adjusted.csv")
    for pid in example_ids:
        files.download(f"{pid}_trend_adjusted.png")